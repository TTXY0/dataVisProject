{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title of Final Project: Child Mind Institute - Detect Sleep States\n",
    "\n",
    "Section: 52745\n",
    "\n",
    "\n",
    "Student Name: Thomas Wynn\n",
    "\n",
    "Student UT EID: ttw483\n",
    "\n",
    "Date: 10/30/23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "import gc\n",
    "\n",
    "train_events_path = \"/Users/thomaswynn/Desktop/sleep_kaggle/child-mind-institute-detect-sleep-states/train_events.csv\"\n",
    "train_series_path = \"/Users/thomaswynn/Desktop/sleep_kaggle/child-mind-institute-detect-sleep-states/train_series.parquet\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory reduction for train_series\n",
    "#The following function has been taken from the notebook\n",
    "# https://www.kaggle.com/code/renatoreggiani/zzzs-feat-eng-ideas-60-memory-reduction?scriptVersionId=143987308\n",
    "\n",
    "from pandas.api.types import is_datetime64_ns_dtype\n",
    "import gc\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \n",
    "    \"\"\" \n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == 'timestamp' or col == 'date' or col == 'time' : continue\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object and not is_datetime64_ns_dtype(df[col]):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        \n",
    "\n",
    "    df['series_id'] = df['series_id'].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f'Decreased by {decrease:.2f}%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a list 'dt_transforms' with transformations \n",
    "## to be applied to a timestamp column in the data\n",
    "dt_transforms = [\n",
    "   pl.col('timestamp').str.to_datetime(), \n",
    "   (pl.col('timestamp').str.to_datetime().dt.date()).alias('date'), \n",
    "   pl.col('timestamp').str.to_datetime().dt.time().alias('time')\n",
    "]\n",
    "\n",
    "trn_series = (\n",
    "   pl.scan_parquet(train_series_path)\n",
    "   .with_columns((dt_transforms))\n",
    "   .collect()\n",
    "   .to_pandas()\n",
    ")\n",
    "\n",
    "trn_events = (\n",
    "   pl.scan_csv(train_events_path)\n",
    "   .with_columns((dt_transforms))\n",
    "   .collect()\n",
    "   .to_pandas()\n",
    ")\n",
    "\n",
    "# # download test_series data\n",
    "# tst_series = (\n",
    "#    pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet')\n",
    "#    .with_columns((dt_transforms))\n",
    "#    .collect()\n",
    "#    .to_pandas()\n",
    "# )\n",
    "\n",
    "reduce_mem_usage(trn_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in trn_series.columns :\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_datetime64_ns_dtype((trn_series.time[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_series = trn_events.groupby('series_id')['step'].apply(lambda x: x.isnull().any())\n",
    "no_nan_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_series = no_nan_series.drop('31011ade7c0a') # incomplete events data\n",
    "no_nan_series = no_nan_series.drop('a596ad0b82aa') # incomplete events data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_series = no_nan_series[~no_nan_series].index.tolist()\n",
    "no_nan_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this function, we are combining train_series with train_events to create a binary dataset, for a given series ID. Time points where the individual are asleep are labeled 1 and awake, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_series(series): # takes in a series ID and returns\n",
    "    train_series = pd.read_parquet(train_series_path, filters=[('series_id','==',series)])\n",
    "    train_events = pd.read_csv(train_events_path).query('series_id == @series')\n",
    "    \n",
    "    train_events = train_events.dropna()\n",
    "    train_events[\"step\"]  = train_events[\"step\"].astype(\"int\")\n",
    "    train_events[\"awake\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
    "\n",
    "    train = pd.merge(train_series, train_events[['step','awake']], on='step', how='left')\n",
    "    train[\"awake\"] = train[\"awake\"].bfill(axis ='rows')\n",
    "\n",
    "    train['awake'] = train['awake'].fillna(1) # awake\n",
    "    train[\"awake\"] = train[\"awake\"].astype(\"int\")\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets visualize this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_train_data = []\n",
    "\n",
    "for series_id in no_nan_series:\n",
    "    train = get_train_series(series_id)\n",
    "    smaller_train_data.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_size_dict = {id : size for (id,size) in zip([dataframe.series_id.unique()[0] for dataframe in smaller_train_data], [len(dataframe) for dataframe in smaller_train_data])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for series_id in no_nan_series : \n",
    "    if series_id == \"349c5562ee2c\":\n",
    "        print(index)\n",
    "        break\n",
    "    else : index += 1\n",
    "min(series_size_dict, key = series_size_dict.get)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(series_size_dict, key = series_size_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Slider\n",
    "%matplotlib inline\n",
    "data = smaller_train_data[-8]\n",
    "series_id = data.series_id.unique()[0]\n",
    "series_events = trn_events[trn_events.series_id == series_id]\n",
    "wake_steps = series_events[series_events.event == 'wakeup'].timestamp\n",
    "onset_steps = series_events[series_events.event == 'onset'].timestamp\n",
    "\n",
    "awake_changes = data.awake.diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "enmo_df = data.enmo.resample(\"60S\").mean().to_frame(name = 'enmo')\n",
    "anglez_df = data.anglez.resample(\"60S\").mean().to_frame(name = 'anglez')\n",
    "\n",
    "awake_enmo = data.awake.resample(\"60S\").mean()\n",
    "awake_anglez = data.awake.resample(\"60S\").mean()\n",
    "\n",
    "awake_enmo = awake_enmo.reset_index()\n",
    "awake_anglez = awake_anglez.reset_index()\n",
    "\n",
    "awake_enmo = awake_enmo.drop('timestamp', axis = 1)\n",
    "awake_anglez = awake_anglez.drop('timestamp', axis = 1)\n",
    "\n",
    "enmo_df = pd.concat((enmo_df.reset_index(), awake_enmo), axis = 1)\n",
    "anglez_df = pd.concat((anglez_df.reset_index(), awake_anglez), axis = 1)\n",
    "\n",
    "\n",
    "def makezero(value) : \n",
    "    if value < 1:\n",
    "        return 0\n",
    "    else : return 1\n",
    "        \n",
    "enmo_df.awake = enmo_df.awake.apply(lambda val : makezero(val))\n",
    "anglez_df.awake = anglez_df.awake.apply(lambda val : makezero(val))\n",
    "enmo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "wake_steps_df = wake_steps.to_frame(name='timestamp')\n",
    "onset_steps_df = onset_steps.to_frame(name='timestamp')\n",
    "\n",
    "\n",
    "interval = alt.selection_interval(encodings=['x'])\n",
    "\n",
    "base = alt.Chart(enmo_df.reset_index()).mark_line().encode(\n",
    "    x = 'timestamp:T',\n",
    "    y = 'enmo:Q',\n",
    "    color = alt.Color('awake:N')\n",
    ").properties (\n",
    "    width = 1500,\n",
    "    height = 250\n",
    ")\n",
    "\n",
    "base2 = alt.Chart(anglez_df.reset_index()).mark_line().encode(\n",
    "    x = 'timestamp:T',\n",
    "    y = 'anglez:Q',\n",
    "    color = alt.Color('awake:N')\n",
    ").properties (\n",
    "    width = 1500,\n",
    "    height = 250\n",
    ")\n",
    "\n",
    "rule1 = alt.Chart(wake_steps_df).mark_rule(\n",
    "    color=\"green\",\n",
    "    strokeWidth=3,\n",
    "    strokeDash=[20, 1]\n",
    ").encode(\n",
    "    x=\"timestamp:T\",\n",
    ")\n",
    "\n",
    "rule2 = alt.Chart(onset_steps_df).mark_rule(\n",
    "    color=\"red\",\n",
    "    strokeWidth=3,\n",
    "    strokeDash=[20, 1]\n",
    ").encode(\n",
    "    x=\"timestamp:T\",\n",
    ")\n",
    "\n",
    "\n",
    "top = base + rule1 + rule2\n",
    "top2 = base2 + rule1 + rule2\n",
    "\n",
    "chart = top.encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=interval))\n",
    ")\n",
    "\n",
    "chart2 = top2.encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=interval))\n",
    ")\n",
    "\n",
    "view = base.add_selection(\n",
    "    interval\n",
    ").properties (\n",
    "    height = 50,\n",
    "    width = 1500\n",
    ")\n",
    "\n",
    "(chart2 & chart & view).configure_axis(\n",
    "    grid=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "my_colors = [\"#f79256\", \"#fbd1a2\", \"#7dcfb6\", \"#00b2ca\"]\n",
    "trn_events[\"time\"] = trn_events.timestamp.dt.time\n",
    "\n",
    "\n",
    "df = trn_events.copy()\n",
    "df.time = pd.to_datetime(df.time, format='%H:%M:%S')\n",
    "df.set_index(['time'],inplace=True)\n",
    "df.event = df.event.astype(str)\n",
    "\n",
    "df.event = df.event.astype(str)\n",
    "\n",
    "def change_event_numeric(event):\n",
    "    if event == \"onset\":\n",
    "        return 1\n",
    "    if event == \"wakeup\":\n",
    "        return 2\n",
    "    \n",
    "df.event = df.event.apply(change_event_numeric)\n",
    "\n",
    "def jitter(values,j= 0.01):\n",
    "    return values + np.random.normal(j,0.05,values.shape)\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(\n",
    "    x=df.index,\n",
    "    y=jitter(df[\"event\"], 0.01),\n",
    "    color=df[\"event\"],\n",
    "    size=df[\"event\"] + 4,\n",
    "    color_continuous_scale = px.colors.qualitative.D3\n",
    ")\n",
    "\n",
    "# Set the title and axis labels\n",
    "fig.update_layout(\n",
    "    title=\"Times for onset & wakeup\",\n",
    "    xaxis_title=\"time\",\n",
    "    yaxis_title=\"event type\",\n",
    "    width = 1500,\n",
    "    height = 500,\n",
    "    yaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [1, 2],\n",
    "        ticktext = ['Onset of Asleep', 'Wake up']\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.update_xaxes(showline=False, linewidth=0, linecolor='black', gridcolor='black', gridwidth= 10)\n",
    "fig.update_yaxes(showline=False, linewidth=0, linecolor='black', gridcolor='black', gridwidth= 4)\n",
    "\n",
    "# Rotate the x-axis ticks\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_signal_clean(signal, filter_percent=99.7, f=0.2, show_plot=False, y_min=0, y_max=1, L_min_idx=0, L_max_idx=-1):\n",
    "    \"\"\"\n",
    "    Denoising signal using Fast Fourier Transformation\n",
    "    Adapted from: https://www.youtube.com/watch?v=s2K1JfNR7Sc\n",
    "    \n",
    "    All errors are mine.\n",
    "    \"\"\"\n",
    "    t = np.arange(0,1,f)\n",
    "    \n",
    "    # Get signal length\n",
    "    n = len(signal)\n",
    "    \n",
    "    # Compute the FFT\n",
    "    fhat = np.fft.fft(signal, n)\n",
    "    \n",
    "    # Compute Power Spectrum\n",
    "    PSD = fhat * np.conj(fhat) / n\n",
    "    print(PSD)\n",
    "    # Create x-axis of frequencies\n",
    "    freq = (1 / (f * n)) * np.arange(n)\n",
    "    \n",
    "    PSD_filter = np.percentile(PSD.real, filter_percent)\n",
    "    \n",
    "    # For graphing\n",
    "    if show_plot:\n",
    "        L = np.arange(1, np.floor(n/2), dtype='int')\n",
    "        fig,axs = plt.subplots(1,1)\n",
    "        plt.sca(axs)\n",
    "        plt.plot(freq[L], PSD[L], color='c', linewidth=2, label='Noisy')\n",
    "        axs.axhline(\n",
    "            y=PSD_filter,\n",
    "            color='red'\n",
    "        )\n",
    "        ## Limits on y-axis\n",
    "        plt.ylim(y_min, y_max)\n",
    "        \n",
    "        ## Limits on x-axis\n",
    "        plt.xlim(freq[L[L_min_idx]]-0.1, freq[L[L_max_idx]]+0.1)\n",
    "        plt.legend()\n",
    "        plt.title(\"PSD\")\n",
    "        plt.show()\n",
    "    \n",
    "    indices = PSD >= PSD_filter\n",
    "    \n",
    "    # For graphing\n",
    "    if show_plot:\n",
    "        PSD_clean = PSD * indices\n",
    "    \n",
    "    fhat = fhat * indices\n",
    "    \n",
    "    # Compute inverse FFT\n",
    "    signal_clean = np.fft.ifft(fhat)\n",
    "    \n",
    "    return signal_clean.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series, s_lbls, column='enmo'):\n",
    "    \"\"\"\n",
    "    Plot the selected column and the accompanying events\n",
    "    \"\"\"\n",
    "    # assert column in s.columns, \"Invalid column.\"\n",
    "    \n",
    "    ymin = series[column].min()\n",
    "    ymax = series[column].max()\n",
    "    \n",
    "    color = '#F8C471'\n",
    "\n",
    "    color_onset = '#196F3D'\n",
    "    color_wakeup = '#943126'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "    ax.plot(series.step, series[column], color=color)\n",
    "\n",
    "    # Apply label\n",
    "    for r in s_lbls[['event', 'step']].itertuples():\n",
    "        ax.axvline(x=r.step,\n",
    "                   ymin=min(0, ymin),\n",
    "                   ymax=max(1, ymax),\n",
    "                   linewidth=2.,\n",
    "                   linestyle='--',\n",
    "                   color=color_onset if r.event == 'onset' else color_wakeup)\n",
    "\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel(column, color=color, fontsize = 14)\n",
    "    fig.suptitle(f'{column} for {series.series_id.iloc[0]}', fontsize = 20)\n",
    "    fig.autofmt_xdate()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_id = trn_events.series_id[0]\n",
    "\n",
    "s = trn_series.query(f\"`series_id`=='{series_id}'\")\n",
    "s_lbls = trn_events.query(f\"`series_id`=='{series_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_series['anglez_norm'] = tst_series['anglez'] / 90.\n",
    "trn_series['anglez_norm'] = trn_series['anglez'] / 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_percentages = [0, 50, 75, 99.7, 99.9, 99.95, 99.99, 99.999]\n",
    "s['anglez_norm'] = s['anglez'] / 90.\n",
    "for i in  range(len(filter_percentages) ) : \n",
    "    s[f'enmo_clean{i}'] = fft_signal_clean(s.enmo.values, filter_percent=filter_percentages[i], show_plot=False, y_min=0, y_max=2, L_min_idx=0, L_max_idx=50);\n",
    "    s[f'anglez_clean{i}'] = fft_signal_clean(s.anglez_norm.values, filter_percent=filter_percentages[i], show_plot=False, y_min=0, y_max=2, L_min_idx=0, L_max_idx=50);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = make_blobs(centers=[[0, 0], [1, 1]], random_state=61526, n_samples=1000)\n",
    "\n",
    "\n",
    "def plot_forest(max_depth=1):\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    h = 0.02\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    if max_depth != 0:\n",
    "        forest = RandomForestClassifier(n_estimators=20, max_depth=max_depth,\n",
    "                                        random_state=1).fit(X, y)\n",
    "        Z = forest.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, alpha=.4)\n",
    "        ax.set_title(\"max_depth = %d\" % max_depth)\n",
    "    else:\n",
    "        ax.set_title(\"data set\")\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=np.array(['b', 'r'])[y], s=60)\n",
    "    ax.set_xlabel(\"PCA 1\")\n",
    "    ax.set_ylabel(\"PCA 2\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "def plot_forest_interactive():\n",
    "    from ipywidgets import interactive, IntSlider\n",
    "    slider = IntSlider(min=0, max=5, step=1, value=0)\n",
    "    return interactive(plot_forest, max_depth=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forest_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "def make_features(df):\n",
    "    # parse the timestamp and create an \"hour\" feature\n",
    "    print((pd.to_datetime(df['timestamp'])[0]))\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t : t.replace(tzinfo=None))\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    \n",
    "    periods = 20\n",
    "    df[\"anglez\"] = abs(df[\"anglez\"])\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"enmo_diff\"] = df.groupby('series_id')['enmo'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"anglez_rolling_mean\"] = df[\"anglez\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_mean\"] = df[\"enmo\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_max\"] = df[\"anglez\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_max\"] = df[\"enmo\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_std\"] = df[\"anglez\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_std\"] = df[\"enmo\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_mean\"] = df[\"anglez_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_mean\"] = df[\"enmo_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_max\"] = df[\"anglez_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_max\"] = df[\"enmo_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    \n",
    "    return df\n",
    "\n",
    "features = [\"hour\",\n",
    "            \"anglez\",\n",
    "            \"anglez_rolling_mean\",\n",
    "            \"anglez_rolling_max\",\n",
    "            \"anglez_rolling_std\",\n",
    "            \"anglez_diff\",\n",
    "            \"anglez_diff_rolling_mean\",\n",
    "            \"anglez_diff_rolling_max\",\n",
    "            \"enmo\",\n",
    "            \"enmo_rolling_mean\",\n",
    "            \"enmo_rolling_max\",\n",
    "            \"enmo_rolling_std\",\n",
    "            \"enmo_diff\",\n",
    "            \"enmo_diff_rolling_mean\",\n",
    "            \"enmo_diff_rolling_max\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzz_series = pd.read_parquet(\"/Users/thomaswynn/Desktop/sleep_kaggle/Zzzs_train_multi.parquet\").iloc[::10, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "\n",
    "train   = make_features(zzz_series)\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"awake\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_RF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=5,\n",
    "                                    min_samples_leaf=300,\n",
    "                                    random_state=42,n_jobs=-1, max_depth= 1)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# save some memory\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fn=list(X_train.columns)\n",
    "cn= list(y_train.unique().astype(str))\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "tree.plot_tree(classifier.estimators_[0],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.patch.set_alpha(0)\n",
    "fig.savefig('rf_individualtree.png', transparent= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=list(X_train.columns)\n",
    "cn= list(y_train.unique().astype(str))\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 3,figsize = (40,10), dpi = 450)\n",
    "for index in range(0, 3):\n",
    "    tree.plot_tree(classifier.estimators_[index],\n",
    "                   feature_names = fn, \n",
    "                   class_names=cn,\n",
    "                   filled = True,\n",
    "                   ax = axes[index]);\n",
    "    for line in axes[index].get_lines():\n",
    "        line.set_color(\"white\")\n",
    "    axes[index].patch.set_alpha(0)\n",
    "    axes[index].title.set_color(\"white\")\n",
    "    axes[index].set_title('Estimator: ' + str(index + 1), fontsize = 30)\n",
    "fig.savefig('rf_5trees.png', transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
